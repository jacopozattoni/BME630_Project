{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacopozattoni/BME630_Project/blob/main/Project_BME_630.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "azEEzAhpWar0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD141V3kVGD0"
      },
      "outputs": [],
      "source": [
        "# Imports:\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from sklearn.metrics import balanced_accuracy_score, adjusted_rand_score, roc_auc_score\n",
        "import warnings\n",
        "import requests\n",
        "import os\n",
        "from PIL import Image, ImageFilter\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miseval functions\n",
        "Taken from: https://github.com/frankkramer-lab/miseval . Miseval is a python package that implements evaluation metrics for image segmentation tasks; it relies on numpy and scikit learn. In the project it is used to calculate the dice and the jaccard scores for the segmentations obtained from the network, as well as traditional metrics such as accuracy, precision, sensitivity and specificity.\n",
        "\n",
        "Its functions are imported manually instead of importing the package because of compatibility issues between numpy and one of the required packages for miseval, numba."
      ],
      "metadata": {
        "id": "G1734kmSWgZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#==============================================================================#\n",
        "#  Author:       Dominik Müller                                                #\n",
        "#  Copyright:    2022 IT-Infrastructure for Translational Medical Research,    #\n",
        "#                University of Augsburg                                        #\n",
        "#                                                                              #\n",
        "#  This program is free software: you can redistribute it and/or modify        #\n",
        "#  it under the terms of the GNU General Public License as published by        #\n",
        "#  the Free Software Foundation, either version 3 of the License, or           #\n",
        "#  (at your option) any later version.                                         #\n",
        "#                                                                              #\n",
        "#  This program is distributed in the hope that it will be useful,             #\n",
        "#  but WITHOUT ANY WARRANTY; without even the implied warranty of              #\n",
        "#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the               #\n",
        "#  GNU General Public License for more details.                                #\n",
        "#                                                                              #\n",
        "#  You should have received a copy of the GNU General Public License           #\n",
        "#  along with this program.  If not, see <http://www.gnu.org/licenses/>.       #\n",
        "#==============================================================================#\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#            Calculate : Precision via Sets           #\n",
        "#-----------------------------------------------------#\n",
        "def calc_Precision_Sets(truth, pred, c=1, **kwargs):\n",
        "    # Obtain sets with associated class\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    # Calculate precision\n",
        "    if pd.sum() != 0 : prec = np.logical_and(pd, gt).sum() / pd.sum()\n",
        "    else : prec = 0.0\n",
        "    # Return precision\n",
        "    return prec\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#             Calculate : Precision via CM            #\n",
        "#-----------------------------------------------------#\n",
        "def calc_Precision_CM(truth, pred, c=1, **kwargs):\n",
        "    # Obtain confusion matrix\n",
        "    tp, tn, fp, fn = calc_ConfusionMatrix(truth, pred, c)\n",
        "    # Calculate precision\n",
        "    if (tp + fp) != 0 : prec = (tp) / (tp + fp)\n",
        "    else : prec = 0.0\n",
        "    # Return precision\n",
        "    return prec\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#           Calculate : Sensitivity via Sets          #\n",
        "#-----------------------------------------------------#\n",
        "def calc_Sensitivity_Sets(truth, pred, c=1, **kwargs):\n",
        "    # Obtain sets with associated class\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    # Calculate sensitivity\n",
        "    if gt.sum() != 0 : sens = np.logical_and(pd, gt).sum() / gt.sum()\n",
        "    else : sens = 0.0\n",
        "    # Return sensitivity\n",
        "    return sens\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#            Calculate : Sensitivity via CM           #\n",
        "#-----------------------------------------------------#\n",
        "def calc_Sensitivity_CM(truth, pred, c=1, **kwargs):\n",
        "    # Obtain confusion matrix\n",
        "    tp, tn, fp, fn = calc_ConfusionMatrix(truth, pred, c)\n",
        "    # Calculate sensitivity\n",
        "    if (tp + fn) != 0 : sens = (tp) / (tp + fn)\n",
        "    else : sens = 0.0\n",
        "    # Return sensitivity\n",
        "    return sens\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#           Calculate : Specificity via Sets          #\n",
        "#-----------------------------------------------------#\n",
        "def calc_Specificity_Sets(truth, pred, c=1, **kwargs):\n",
        "    # Obtain sets with associated class\n",
        "    not_gt = np.logical_not(np.equal(truth, c))\n",
        "    not_pd = np.logical_not(np.equal(pred, c))\n",
        "    # Calculate specificity\n",
        "    if (not_gt).sum() != 0:\n",
        "        spec = np.logical_and(not_pd, not_gt).sum() / (not_gt).sum()\n",
        "    else : spec = 0.0\n",
        "    # Return specificity\n",
        "    return spec\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#            Calculate : Specificity via CM           #\n",
        "#-----------------------------------------------------#\n",
        "def calc_Specificity_CM(truth, pred, c=1, **kwargs):\n",
        "    # Obtain confusion matrix\n",
        "    tp, tn, fp, fn = calc_ConfusionMatrix(truth, pred, c)\n",
        "    # Calculate specificity\n",
        "    if (tn + fp) != 0 : spec = (tn) / (tn + fp)\n",
        "    else : spec = 0.0\n",
        "    # Return specificity\n",
        "    return spec\n",
        "\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#            Calculate : Accuracy via Sets            #\n",
        "#-----------------------------------------------------#\n",
        "def calc_Accuracy_Sets(truth, pred, c=1, **kwargs):\n",
        "    # Obtain sets with associated class\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    not_gt = np.logical_not(gt)\n",
        "    not_pd = np.logical_not(pd)\n",
        "    # Calculate Accuracy\n",
        "    acc = (np.logical_and(pd, gt).sum() + \\\n",
        "           np.logical_and(not_pd, not_gt).sum()) / gt.size\n",
        "    # Return computed Accuracy\n",
        "    return acc\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#           Calculate : Accuracy via ConfMat          #\n",
        "#-----------------------------------------------------#\n",
        "def calc_Accuracy_CM(truth, pred, c=1, **kwargs):\n",
        "    # Obtain confusion mat\n",
        "    tp, tn, fp, fn = calc_ConfusionMatrix(truth, pred, c)\n",
        "    # Calculate Accuracy\n",
        "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
        "    # Return computed Accuracy\n",
        "    return acc\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#            Calculate : AUC via trapezoid            #\n",
        "#-----------------------------------------------------#\n",
        "\"\"\"\n",
        "Formula:\n",
        "    AUC = 1 - 1/2 * (FP/(FP+TN) + FN/(FN+TP))\n",
        "\n",
        "References:\n",
        "    Powers DMW. Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation.\n",
        "    2020 Oct 10 [cited 2022 Jan 8]; Available from: http://arxiv.org/abs/2010.16061\n",
        "\"\"\"\n",
        "def calc_AUC_trapezoid(truth, pred, c=1, **kwargs):\n",
        "    # Obtain confusion mat\n",
        "    tp, tn, fp, fn = calc_ConfusionMatrix(truth, pred, c)\n",
        "    # Compute AUC\n",
        "    if (fp+tn) != 0 : x = fp/(fp+tn)\n",
        "    else : x = 0.0\n",
        "    if (fn+tp) != 0 : y = fn/(fn+tp)\n",
        "    else : y = 0.0\n",
        "    auc = 1 - (1/2)*(x + y)\n",
        "    # Return AUC\n",
        "    return auc\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#           Calculate : AUC via probability           #\n",
        "#-----------------------------------------------------#\n",
        "def calc_AUC_probability(truth, pred_prob, c=1, rounding_precision=5, **kwargs):\n",
        "    # Round probability to reduce unnecessary thresholds\n",
        "    prob = np.round(pred_prob[:,:,c], rounding_precision)\n",
        "    # Obtain ground truth set with associated class\n",
        "    gt = np.equal(truth, c).astype(int)\n",
        "    auc = roc_auc_score(gt.flatten(), prob.flatten())\n",
        "    # Return AUC\n",
        "    return auc\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#            Calculate : Balanced Accuracy            #\n",
        "#-----------------------------------------------------#\n",
        "\"\"\"\n",
        "Formula:\n",
        "    BACC = (Sensitivity + Specificity) / 2\n",
        "\n",
        "References:\n",
        "[1] Brodersen, K.H.; Ong, C.S.; Stephan, K.E.; Buhmann, J.M. (2010).\n",
        "    The balanced accuracy and its posterior distribution.\n",
        "    Proceedings of the 20th International Conference on Pattern Recognition, 3121-24.\n",
        "\n",
        "[2] John. D. Kelleher, Brian Mac Namee, Aoife D’Arcy, (2015).\n",
        "    Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies.\n",
        "    https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics\n",
        "\"\"\"\n",
        "def calc_BalancedAccuracy(truth, pred, c=1, **kwargs):\n",
        "    # Obtain sets with associated class\n",
        "    gt = np.equal(truth, c).flatten()\n",
        "    pd = np.equal(pred, c).flatten()\n",
        "    # Compute BACC via scikit-learn\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        bacc = balanced_accuracy_score(gt, pd)\n",
        "    # Return BACC score\n",
        "    return np.float64(bacc)\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#           Calculate : Adjusted Rand Index           #\n",
        "#-----------------------------------------------------#\n",
        "\"\"\"\n",
        "Formula:\n",
        "    ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)\n",
        "\n",
        "References:\n",
        "[1] L. Hubert and P. Arabie, Comparing Partitions, Journal of Classification 1985\n",
        "    https://link.springer.com/article/10.1007%2FBF01908075\n",
        "\n",
        "\n",
        "[2] D. Steinley, Properties of the Hubert-Arabie adjusted Rand index,\n",
        "    Psychological Methods 2004\n",
        "\n",
        "[3] https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index\n",
        "\"\"\"\n",
        "def calc_AdjustedRandIndex(truth, pred, c=1, **kwargs):\n",
        "    # Obtain sets with associated class\n",
        "    gt = np.equal(truth, c).flatten()\n",
        "    pd = np.equal(pred, c).flatten()\n",
        "    # Compute ARI via scikit-learn\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        ari = adjusted_rand_score(gt, pd)\n",
        "    # Return ARI score\n",
        "    return np.float64(ari)\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#            Calculate : Confusion Matrix             #\n",
        "#-----------------------------------------------------#\n",
        "def calc_ConfusionMatrix(truth, pred, c=1, dtype=np.int64, **kwargs):\n",
        "    # Obtain predicted and actual condition\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    not_gt = np.logical_not(gt)\n",
        "    not_pd = np.logical_not(pd)\n",
        "    # Compute Confusion Matrix\n",
        "    tp = np.logical_and(pd, gt).sum()\n",
        "    tn = np.logical_and(not_pd, not_gt).sum()\n",
        "    fp = np.logical_and(pd, not_gt).sum()\n",
        "    fn = np.logical_and(not_pd, gt).sum()\n",
        "    # Convert to desired numpy type to avoid overflow\n",
        "    tp = tp.astype(dtype)\n",
        "    tn = tn.astype(dtype)\n",
        "    fp = fp.astype(dtype)\n",
        "    fn = fn.astype(dtype)\n",
        "    # Return Confusion Matrix\n",
        "    return tp, tn, fp, fn\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#              Calculate : True Positive              #\n",
        "#-----------------------------------------------------#\n",
        "def calc_TruePositive(truth, pred, c=1, **kwargs):\n",
        "    # Obtain predicted and actual condition\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    not_gt = np.logical_not(gt)\n",
        "    not_pd = np.logical_not(pd)\n",
        "    # Compute true positive\n",
        "    tp = np.logical_and(pd, gt).sum()\n",
        "    # Return true positive\n",
        "    return tp\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#              Calculate : True Negative              #\n",
        "#-----------------------------------------------------#\n",
        "def calc_TrueNegative(truth, pred, c=1, **kwargs):\n",
        "    # Obtain predicted and actual condition\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    not_gt = np.logical_not(gt)\n",
        "    not_pd = np.logical_not(pd)\n",
        "    # Compute true negative\n",
        "    tn = np.logical_and(not_pd, not_gt).sum()\n",
        "    # Return true negative\n",
        "    return tn\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#              Calculate : False Positive             #\n",
        "#-----------------------------------------------------#\n",
        "def calc_FalsePositive(truth, pred, c=1, **kwargs):\n",
        "    # Obtain predicted and actual condition\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    not_gt = np.logical_not(gt)\n",
        "    not_pd = np.logical_not(pd)\n",
        "    # Compute false positive\n",
        "    fp = np.logical_and(pd, not_gt).sum()\n",
        "    # Return false positive\n",
        "    return fp\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#              Calculate : False Negative             #\n",
        "#-----------------------------------------------------#\n",
        "def calc_FalseNegative(truth, pred, c=1, **kwargs):\n",
        "    # Obtain predicted and actual condition\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    not_gt = np.logical_not(gt)\n",
        "    not_pd = np.logical_not(pd)\n",
        "    # Compute false negative\n",
        "    fn = np.logical_and(not_pd, gt).sum()\n",
        "    # Return false negative\n",
        "    return fn\n",
        "\n",
        "\n",
        "# Dice score calculator: -------------------------------------------------------\n",
        "#-----------------------------------------------------#\n",
        "#              Calculate : DSC Enhanced               #\n",
        "#-----------------------------------------------------#\n",
        "\"\"\"\n",
        "    Reference:  Dominik Müller, Adrian Pfleiderer & Frank Kramer. (2022).\n",
        "                miseval: a metric library for Medical Image Segmentation EVALuation.\n",
        "                https://github.com/frankkramer-lab/miseval\n",
        "\n",
        "    Custom Dice Similarity Coefficient implementation which returns 1.0,\n",
        "    if two empty masks are compared.\n",
        "    This allow rewarding models which correctly predict empty masks.\n",
        "\"\"\"\n",
        "def calc_DSC_Enhanced(truth, pred, c=1, **kwargs):\n",
        "    # Obtain sets with associated class\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    # Calculate Dice\n",
        "    if gt.sum() == 0 and pd.sum() == 0 : dice = 1.0\n",
        "    elif (pd.sum() + gt.sum()) != 0:\n",
        "        dice = 2*np.logical_and(pd, gt).sum() / (pd.sum() + gt.sum())\n",
        "    else : dice = 0.0\n",
        "    # Return computed Dice\n",
        "    return dice\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#              Calculate : DSC via Sets               #\n",
        "#-----------------------------------------------------#\n",
        "def calc_DSC_Sets(truth, pred, c=1, **kwargs):\n",
        "    # Obtain sets with associated class\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    # Calculate Dice\n",
        "    if (pd.sum() + gt.sum()) != 0:\n",
        "        dice = 2*np.logical_and(pd, gt).sum() / (pd.sum() + gt.sum())\n",
        "    else : dice = 0.0\n",
        "    # Return computed Dice\n",
        "    return dice\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#             Calculate : DSC via ConfMat             #\n",
        "#-----------------------------------------------------#\n",
        "def calc_DSC_CM(truth, pred, c=1, **kwargs):\n",
        "    # Obtain confusion mat\n",
        "    tp, tn, fp, fn = calc_ConfusionMatrix(truth, pred, c)\n",
        "    # Calculate Dice\n",
        "    if (2*tp + fp + fn) != 0 : dice = 2*tp / (2*tp + fp + fn)\n",
        "    else : dice = 0.0\n",
        "    # Return computed Dice\n",
        "    return dice\n",
        "\n",
        "# Jaccard score calculator: -----------------------------------------------------\n",
        "#-----------------------------------------------------#\n",
        "#              Calculate : IoU via Sets               #\n",
        "#-----------------------------------------------------#\n",
        "def calc_IoU_Sets(truth, pred, c=1, **kwargs):\n",
        "    # Obtain sets with associated class\n",
        "    gt = np.equal(truth, c)\n",
        "    pd = np.equal(pred, c)\n",
        "    # Calculate IoU\n",
        "    if  (pd.sum() + gt.sum() - np.logical_and(pd, gt).sum()) != 0:\n",
        "        iou = np.logical_and(pd, gt).sum() / \\\n",
        "              (pd.sum() + gt.sum() - np.logical_and(pd, gt).sum())\n",
        "    else : iou = 0.0\n",
        "    # Return computed IoU\n",
        "    return iou\n",
        "\n",
        "#-----------------------------------------------------#\n",
        "#             Calculate : IoU via ConfMat             #\n",
        "#-----------------------------------------------------#\n",
        "def calc_IoU_CM(truth, pred, c=1, **kwargs):\n",
        "    # Obtain confusion mat\n",
        "    tp, tn, fp, fn = calc_ConfusionMatrix(truth, pred, c)\n",
        "    # Calculate IoU\n",
        "    if (tp + fp + fn) != 0 : iou = tp / (tp + fp + fn)\n",
        "    else : iou = 0.0\n",
        "    # Return computed IoU\n",
        "    return iou\n",
        "\n",
        "# Miseval Evaluate function: ---------------------------------------------------------\n",
        "def mis_evaluate(truth, pred, metric, multi_class=False, n_classes=2, **kwargs):\n",
        "    # Initialize metric function\n",
        "    if isinstance(metric, str):\n",
        "        if metric in metric_dict : eval_metric = metric_dict[metric]\n",
        "        elif metric.upper() in metric_dict:\n",
        "            eval_metric = metric_dict[metric.upper()]\n",
        "        else : raise KeyError(\"Provided metric string not in metric_dict!\" + \\\n",
        "                              \" : \" + metric)\n",
        "    elif callable(metric) : eval_metric = metric\n",
        "    else : raise ValueError(\"Provided metric is neither a function nor a \" + \\\n",
        "                            \"string!\" + \" : \" + str(metric))\n",
        "    # Check some Exceptions\n",
        "    if n_classes == 2 and len(np.unique(truth)) > 2:\n",
        "        raise ValueError(\"Segmentation mask (truth) contains more than 2 classes!\")\n",
        "    if n_classes == 2 and len(np.unique(pred)) > 2:\n",
        "        raise ValueError(\"Segmentation mask (pred) contains more than 2 classes!\")\n",
        "    # Run binary mode       -> Compute score only for main class\n",
        "    if not multi_class and n_classes == 2:\n",
        "        score = eval_metric(truth, pred, c=1, **kwargs)\n",
        "        return score\n",
        "    # Run multi-class mode  -> Compute score for each class\n",
        "    else:\n",
        "        score_list = np.zeros((n_classes,))\n",
        "        for c in range(n_classes):\n",
        "            score = eval_metric(truth, pred, c=c, **kwargs)\n",
        "            score_list[c] = score\n",
        "        return score_list"
      ],
      "metadata": {
        "id": "XFr4MhZaWZdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### My functions\n",
        "This cell contains all the original functions used in the script."
      ],
      "metadata": {
        "id": "hz4fUM0GWlvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# My functions:\n",
        "\n",
        "def create_dir(healthyName, tumorName, parentDir):\n",
        "    \"\"\"\n",
        "    Function to create a new local directory, checking whether it exists or not.\n",
        "    :param healthyName: Healthy class directory name\n",
        "    :param tumorName: Tumor class directory name\n",
        "    :param parentDir: Path to new directory, name of directory excluded.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # Parent Directory path:\n",
        "    parent_dir = parentDir\n",
        "    # Create the directories, but checking if they already exist in the current dir:\n",
        "    if not os.path.exists(os.path.join(parent_dir, healthyName)):\n",
        "        os.mkdir(os.path.join(parent_dir, healthyName))\n",
        "    if not os.path.exists(os.path.join(parent_dir, tumorName)):\n",
        "        os.mkdir(os.path.join(parent_dir, tumorName))\n",
        "\n",
        "def loadImage(name):\n",
        "    \"\"\"\n",
        "    Function to load a Nifti image from a nii.gz zipped file using NiBabel.\n",
        "    :param name: \\Path\\to\\Image\\File\n",
        "    :return: Data = Image data extracted from the nii file.\n",
        "    \"\"\"\n",
        "    # Loading the nifti file using NiBabel:\n",
        "    img = nib.load(name)\n",
        "    # Getting the data of the image as numpy arrays:\n",
        "    Data = img.get_fdata()\n",
        "    return Data\n",
        "\n",
        "def train(net, x, y, loss_function):\n",
        "    \"\"\"\n",
        "    Function to train a ML network.\n",
        "    :param net: Network to be trained.\n",
        "    :param x: Input data for training. It should be 4D tensor, where each 3D entry is a set of the 4 scans of the same brain slice.\n",
        "    :param y: The segmentation masks associated to the input data.\n",
        "    :param loss_function: Function to be used as loss evaluator.\n",
        "    :return loss: loss function value for the input data.\n",
        "    \"\"\"\n",
        "    # clearing the gradients in the network:\n",
        "    optimizer.zero_grad()\n",
        "    # predicting the output for the input data x:\n",
        "    prediction = net(x)\n",
        "    # Evaluating the loss:\n",
        "    Y = torch.zeros(elem_in_batch, 1, 240, 240)\n",
        "    for i in range(elem_in_batch):\n",
        "        Y[i,0,:,:]=y[:,:,i]\n",
        "    loss = loss_function(prediction, Y)\n",
        "    # Calculating the gradient:\n",
        "    loss.backward()\n",
        "    # Adjusting the weight through backpropagation:\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "def validate(net, x, y, loss_function, loss_list):\n",
        "    \"\"\"\n",
        "    Function to validate a trained ML network.\n",
        "    :param net: Trained network.\n",
        "    :param x: Input data for validation. It should be 4D tensor, where each 3D entry is a set of the 4 scans of the same brain slice.\n",
        "    :param y: The segmentation masks associated to the input data.\n",
        "    :param loss_function: Function to be used as loss evaluator.\n",
        "    :param loss_list: List that contains the loss function values for the training.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # Prediction on the validation data:\n",
        "        prediction = net(x)\n",
        "        # loss evaluation:\n",
        "        Y = torch.zeros(x.shape[0], 1, 240, 240)\n",
        "        for i in range(n_batches):\n",
        "            Y[i,0,:,:]=y[:,:,i]\n",
        "        loss = loss_function(prediction, Y)\n",
        "        loss_list.append(loss)\n",
        "\n",
        "def test(net, x, y, n_classes):\n",
        "    \"\"\"\n",
        "    Using the package 'miseval' (https://github.com/frankkramer-lab/miseval) to evaluate the segmentation goodness.\n",
        "    Metrics implemented:\n",
        "    - Dice score: calculated as 2*(# of overlapping pixels)/(# pixels real segmentation + # pixels predicted segmentation).\n",
        "    - Jaccard score: calculated as segmentation overlap / segmentation union.\n",
        "    :param net: Trained network.\n",
        "    :param x: Input data.\n",
        "    :param y: Input segmentation masks.\n",
        "    :param n_classes: # of classes to consider. It is either 2 (simplified segmentation) or 4 (complete segmentation).\n",
        "    :return: dice_list is the list with the dice scores for each predicted mask.\n",
        "    \"\"\"\n",
        "    # Initializing a list to save dice scores for the segmentations:\n",
        "    dice_list = []\n",
        "    Jaccard_list = []\n",
        "    pred = net(x)\n",
        "    # Rearrangement of the reference segmentation masks in the same\n",
        "    Y = torch.zeros(x.shape[0], 1, 240, 240)\n",
        "    for j in range(x.shape[0]):\n",
        "        Y[j,0,:,:]=y[:,:,j]\n",
        "    # Calculates the dice and jaccard scores for each brain slice:\n",
        "    for i in range(x.shape[2]):\n",
        "        if n_classes == 2:\n",
        "            dice_list.append(mis_evaluate(Y[i,0,:,:], pred[i,0,:,:], metric='DSC'))\n",
        "            Jaccard_list.append(mis_evaluate(Y[i,0,:,:], pred[i,0,:,:], metric='IoU'))\n",
        "        else: # since there is a control on n_classes to be either 2 or 4 before in the cose, no additional control on n_classes is made here\n",
        "            dice_list.append(mis_evaluate(Y[i,0,:,:], pred[i,0,:,:], metric='DSC', multi_class=True, n_classes=n_classes))\n",
        "            Jaccard_list.append(mis_evaluate(Y[i,0,:,:], pred[i,0,:,:], metric='IoU', multi_class=True, n_classes=n_classes))\n",
        "\n",
        "    # Whole dataset metrics:\n",
        "    Accuracy = mis_evaluate(Y, pred, metric=\"Accuracy\", multi_class=True, n_classes=n_classes)\n",
        "    Precision = mis_evaluate(Y, pred, metric=\"Precision\", multi_class=True, n_classes=n_classes)\n",
        "    Sensitivity = mis_evaluate(Y, pred, metric=\"Sensitivity\", multi_class=True, n_classes=n_classes)\n",
        "    Specificity = mis_evaluate(Y, pred, metric=\"Specificity\", multi_class=True, n_classes=n_classes)\n",
        "\n",
        "    return dice_list, Jaccard_list, Accuracy, Precision, Sensitivity, Specificity, pred, Y\n",
        "\n",
        "\n",
        "def drawContour(m,s,c,RGB):\n",
        "    \"\"\"Draw edges of contour 'c' from segmented image 's' onto 'm' in colour 'RGB'\"\"\"\n",
        "    # Fill contour \"c\" with white, make all else black\n",
        "    thisContour = s.point(lambda p:p==c and 255)\n",
        "    # DEBUG: thisContour.save(f\"interim{c}.png\")\n",
        "\n",
        "    # Find edges of this contour and make into Numpy array\n",
        "    thisEdges   = thisContour.filter(ImageFilter.FIND_EDGES)\n",
        "    thisEdgesN  = np.array(thisEdges)\n",
        "\n",
        "    # Paint locations of found edges in color \"RGB\" onto \"main\"\n",
        "    m[np.nonzero(thisEdgesN)] = RGB\n",
        "    return m"
      ],
      "metadata": {
        "id": "aIaAKZwuWZRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U-Net architecture\n",
        "SimpleUnet implements a simple U-net architecture made of 5 groups of layers, organized as follows:\n",
        "- 2 groups in the encoding part;\n",
        "- 1 group in the bridging part;\n",
        "- 2 groups in the decoding part.\n",
        "\n",
        "BiggerUnet is a bigger version of SimpleUnet, where the number of layer groups is increased from 2 to 4 for the encoding and the decoding part. This results in a deeper net that is able to generate, at the 5th group of layers (the bridging group between the encoder and the decoder), an array with 1024 'channels' instead of the 256 of the simpler architecture. The idea is to compare the performance of the two to understand what is the benefit of a deeper network in this segmentation context.\n",
        "\n",
        "Both networks take as input an array of dimension [batch_dimension x n_channels x 240 x 240], where batch_dimension = 46 and n_channels = 4 because we are merging the four scan types for the same slice in a single 3D tensor, and output a segmentation mask (hence the # of outputs = 1 in the output layer) that is either binary or a 4-classes mask according to the user's choice."
      ],
      "metadata": {
        "id": "W-EU8TFFWn78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleUnet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(SimpleUnet, self).__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        # Encoder:\n",
        "        # Layer 1:\n",
        "        self.l11 = nn.Conv2d(n_channels, 64, kernel_size=3, padding=1)  # 240x240\n",
        "        self.l12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Layer 2:\n",
        "        self.l21 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 120x120\n",
        "        self.l22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        # Layer 3 - bridge between encoder and decoder:\n",
        "        self.l31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.l32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "\n",
        "        # Decoder:\n",
        "        # Layer 1:\n",
        "        self.upConv1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) # does the opposite as the max pooling layer, hence the same kernel_size and stride\n",
        "        self.l41 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
        "        self.l42 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        # Layer 2:\n",
        "        self.upConv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.l51 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.l52 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        # Layer 3: output layer\n",
        "        self.outConv = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "        # Activation function:\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # if batch normalization is needed, the related layer can be added in the __init__ and called to process the output that is obtained\n",
        "        # after the maxpooling to normalize the input that is provided to the net layer.\n",
        "        # the batch normalization layer would have to be defined for every layer group as torch.nn.BatchNorm2d(n_features), where\n",
        "        # n_features is the number of channels of the input tensor\n",
        "        x1 = self.relu(self.l12(self.relu(self.l11(x)))) # features extracted from the first layer, before the pooling. Saved because we have to pass it to the decoder layer\n",
        "        x2 = self.relu(self.l22(self.relu(self.l21(self.pool1(x1))))) # features extracted from layer 2\n",
        "        x3 = self.relu(self.l32(self.relu(self.l31(self.pool1(x2)))))\n",
        "        x4 = self.upConv1(x3)\n",
        "        x4 = torch.cat((x4, x2), 1) # concatenation along columns\n",
        "        x5 = self.upConv2(self.relu(self.l42(self.relu(self.l41(x4)))))\n",
        "        x5 = torch.cat((x5, x1), 1) # concatenation along columns\n",
        "        out = self.sigmoid(self.outConv(self.relu(self.l52(self.relu(self.l51(x5))))))\n",
        "        if self.n_classes != 2:\n",
        "            out = out*3\n",
        "        return torch.round(out).float() # just to be sure that the round returns a tensor with float values\n",
        "\n",
        "\n",
        "class BiggerUnet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes=4):\n",
        "        super(SimpleUnet, self).__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # Encoder:\n",
        "        # Layer group 1:\n",
        "        self.l11 = nn.Conv2d(n_channels, 64, kernel_size=3, padding=1) # Img size: 240x240x64\n",
        "        self.l12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        # Layer group 2:\n",
        "        self.l21 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 120x120x128\n",
        "        self.l22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        # Layer group 3:\n",
        "        self.l31 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # 60x60x256\n",
        "        self.l32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        # Layer group 4:\n",
        "        self.l41 = nn.Conv2d(256, 512, kernel_size=3, padding=1) # 30x30x512\n",
        "        self.l42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "\n",
        "        # Layer group 5 - bridge between encoder and decoder:\n",
        "        self.l51 = nn.Conv2d(512, 1024, kernel_size=3, padding=1) # 15x15x1024\n",
        "        self.l52 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1)\n",
        "\n",
        "        # Decoder:\n",
        "        # Layer group 1:\n",
        "        self.upConv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.l61 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
        "        self.l62 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        # Layer group 2:\n",
        "        self.upConv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.l71 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
        "        self.l72 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        # Layer group 3:\n",
        "        self.upConv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.l81 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
        "        self.l82 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        # Layer group 4:\n",
        "        self.upConv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.l91 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.l92 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        # Output layer\n",
        "        self.outConv = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "        # Activation function:\n",
        "        self.relu = nn.ReLU()\n",
        "        self.relu = nn.Sigmoid()\n",
        "\n",
        "        # Pooling layer:\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # if batch normalization is needed, the related layer can be added in the __init__ and called to process the output that is obtained\n",
        "        # after the maxpooling to normalize the input that is provided to the net layer.\n",
        "        # the batch normalization layer would have to be defined for every layer group as torch.nn.BatchNorm2d(n_features), where\n",
        "        # n_features is the number of channels of the input tensor\n",
        "        x1 = self.relu(self.l12(self.relu(self.l11(x))))\n",
        "        x2 = self.relu(self.l22(self.relu(self.l21(self.pool(x1)))))\n",
        "        x3 = self.relu(self.l32(self.relu(self.l31(self.pool(x2)))))\n",
        "        x4 = self.relu(self.l42(self.relu(self.l41(self.pool(x3)))))\n",
        "        x5 = self.relu(self.l52(self.relu(self.l51(self.pool(x4)))))\n",
        "        x6 = self.upConv1(x5)\n",
        "        x6 = torch.cat((x6, x4), 1)\n",
        "        x7 = self.upConv2(self.relu(self.l62(self.relu(self.l61(x6)))))\n",
        "        x7 = torch.cat((x7, x3), 1)\n",
        "        x8 = self.upConv2(self.relu(self.l72(self.relu(self.l71(x7)))))\n",
        "        x8 = torch.cat((x8, x2), 1)\n",
        "        x9 = self.upConv2(self.relu(self.l82(self.relu(self.l81(x8)))))\n",
        "        x9 = torch.cat((x9, x1), 1)\n",
        "        out = self.sigmoid(self.outConv(self.relu(self.l92(self.relu(self.l91(x9))))))\n",
        "        if self.n_classes != 2:\n",
        "            out = out*3\n",
        "        return torch.round(out).float() # just to be sure that the round returns a tensor with float values"
      ],
      "metadata": {
        "id": "dGbo_qzmWZD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Local data pre-processing\n",
        "This snippet of code was used to preprocess the dataset provided by kaggle to obtain the tensors with the segmentation masks and the four scan types for each patient. Because of memorization issues, only the first 48 patients out of the 1258 in the dataset were considered. This portion of code also implements the calculation of the areas of the tumor lesions per slice for each class, which can be used as an additional performance evaluator."
      ],
      "metadata": {
        "id": "i_MYHBI5WquI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPROCESSING PART - done in local folders because of the size of the data:\n",
        "#\n",
        "# if __name__ == \"__main__\":\n",
        "#    voxel_dim = 1 # in mm^3\n",
        "#    Datapath = \"C:\\\\Users\\\\jzatt\\\\Desktop\\\\PhD\\\\01_Maral_Course_MachineLearning\\\\00_Project\\\\01_Data\\\\ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData\\\\ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData\"\n",
        "    # Entering in the dir containing the patients scan folders:\n",
        "#    os.chdir(Datapath)\n",
        "    # Getting the folders names as a list:\n",
        "#    IMGFolders = os.listdir(os.getcwd())\n",
        "    # Each folder corresponds to a different patient, and contains:\n",
        "    # - segmentation info (i.e. masks with each pixel's class)\n",
        "    # - T1 whole-brain scan\n",
        "    # - T1 gadolinium contrasted whole-brain scan\n",
        "    # - T2 contrast whole-brain scan\n",
        "    # - T2 FLAIR whole-brain scan\n",
        "\n",
        "#    volumes_dict = {}\n",
        "#    for i in range(len(IMGFolders)): # iterates over all the folders in the main directory\n",
        "#        if IMGFolders[i] == \"BraTS-GLI-00049-000\":\n",
        "#            break # breaking the loop on the folders because of memory issues.\n",
        "        # Entering each patient scans folder:\n",
        "#       os.chdir(IMGFolders[i])\n",
        "#        print(\"Working on folder:\\n\\t- \"+ str(IMGFolders[i]) +\":\" )\n",
        "        # getting the list of nifti.gz zipped folders (each contains one .nii with the whole-brain scan):\n",
        "#        fnames = os.listdir(os.getcwd())\n",
        "        # Iterating over the patients gz folders:\n",
        "#        for name in fnames:\n",
        "#            if \"t2w.nii\" in name or \"t2f.nii\" in name or \"t1n.nii\" in name or \"t1c.nii\" in name or \"seg.nii\" in name: # if the nii.gz folder is as expected\n",
        "#                print(\"\\t Working on file: \"+ str(name))\n",
        "#                imData = loadImage(name)\n",
        "#-------------- WORKING on the segmentation MAKS:\n",
        "#                if \"seg.nii\" in name: # this identifies only the segmentation masks files\n",
        "#                    if i == 0: # i.e., if str(IMGFolders[i]) == str(IMGFolders[0]): if we are in the folder of the first patient, initialize the scans masks tensor:\n",
        "#                        SegIM = torch.tensor(imData) # puts all the segmentation masks in the tensor\n",
        "#                    else: # if it's not the first patient, just append to the existing tensor:\n",
        "#                        SegIM = torch.cat((SegIM, torch.tensor(imData)), 2) # concatenates over dimension 3 (= # of scans) the segmentation scans\n",
        "#------------------ Creating the labels array for ease of indentification of healthy and tumor scans\n",
        "#                    SegClass = []\n",
        "#                    for ind in range(imData.shape[2]): # iterating over the number of scans: each nifti / segmentated file has 240x240 pixels & 155 scans.\n",
        "#                        Nclasses = np.unique(imData[:,:,ind]) # looks at the single scans segmentation to identify the number of classes in it\n",
        "#                        if len(Nclasses) > 1: # since the scans either contain healthy tissue or healthy + tumor tissues, if unique returns only one value it's necessary a 0 (== healthy tissue indicator). If > 1, we have at least one of the three tumor classes in it.\n",
        "#                            SegClass.append(1) # identifies tumor scans\n",
        "#                            for tClass in range(1,4): # saves the volumes of each tumor class in an array\n",
        "#                                if (ind+SegIM.shape[2]-imData.shape[2]) not in volumes_dict:\n",
        "#                                    volumes_dict[ind+SegIM.shape[2]-imData.shape[2]] = {}\n",
        "#                                Label = \"CL_\"+str(tClass)\n",
        "#                                indexes = np.where(imData[:,:,ind]==float(tClass)) # gets the indexes where the segmentation is equal to 1.0, 2.0 or 3.0. It returns an array with two elements: the indexes on the x and y dimensions, so counting one of them equals to counting the total number of pixels of that class in the current scan\n",
        "#                                volumes_dict[ind+SegIM.shape[2]-imData.shape[2]][Label] = len(indexes[0])*voxel_dim # sum(imData[:,:,i][imData[:,:,i]==tClass])*voxel_dim # double sum bc the == creates a boolean mask; the first sum counts per columns, the second per rows\n",
        "#                        else:\n",
        "#                            SegClass.append(0) # identifies healthy scans\n",
        "#                    if i==0: # if looking at the first patient, initialize the reduced labels tensor inserting the first value:\n",
        "#                        Labels = torch.tensor(SegClass) # list with the current patient labels\n",
        "#                    else: # concatenates SegClass to the tensor of the reduced labels\n",
        "#                        Labels = torch.cat((Labels, torch.tensor(SegClass)), 0)\n",
        "#-------------- WORKING on the ACTUAL SCANS:\n",
        "#                else: # if the scans are for T1 or T2 images, contrast and FLAIR comprised:\n",
        "#                    if i == 0: # if it's the first patient, initialize tensors:\n",
        "#                        if \"t1c.nii\" in name:\n",
        "#                            IMGsT1C = torch.tensor(imData) # T1 contrast tensor\n",
        "#                        elif \"t1n.nii\" in name:\n",
        "#                            IMGsT1N = torch.tensor(imData) # T1 normal tensor\n",
        "#                        elif \"t2f.nii\" in name:\n",
        "#                            IMGsT2F = torch.tensor(imData) # T2 FLAIR tensor\n",
        "#                        else: # if \"t2w-nii\" in name:\n",
        "#                            IMGsT2W = torch.tensor(imData) # T2 contrast tensor\n",
        "#                    else: # concatenate scans to already existing tensor:\n",
        "#                        if \"t1c.nii\" in name:\n",
        "#                            IMGsT1C = torch.cat((IMGsT1C, torch.tensor(imData)), dim=-1)\n",
        "#                        elif \"t1n.nii\" in name:\n",
        "#                            IMGsT1N = torch.cat((IMGsT1N, torch.tensor(imData)), dim=-1)\n",
        "#                        elif \"t2f.nii\" in name:\n",
        "#                            IMGsT2F = torch.cat((IMGsT2F, torch.tensor(imData)), dim=-1)\n",
        "#                        else: # if \"t2w-nii\" in name:\n",
        "#                            IMGsT2W = torch.cat((IMGsT2W, torch.tensor(imData)), dim=-1)\n",
        "#                print(\"\\t Done!\")\n",
        "#            else:\n",
        "#                print(\"WARNING!\\n\\tUnable to recognize input nifti file for \"+str(name)+\".\\n\\tExpected the gz folders to end\n",
        "#                with wither t1c.nii, t1n.nii, t2f.nii or t2w.nii. Skipping this folder...\")\n",
        "#        os.chdir(\"../\")\n",
        "\n",
        "#-- Normalization step:\n",
        "#    for s in range(len(Labels)):\n",
        "        # normalization per single scan:\n",
        "#        if (IMGsT1C[:,:,s].max()-IMGsT1C[:,:,s].min()) != 0:\n",
        "#            IMGsT1C[:,:,s] = (IMGsT1C[:,:,s]-IMGsT1C[:,:,s].min())/(IMGsT1C[:,:,s].max()-IMGsT1C[:,:,s].min())\n",
        "#        if (IMGsT1N[:,:,s].max()-IMGsT1N[:,:,s].min()) != 0:\n",
        "#            IMGsT1N[:,:,s] = (IMGsT1N[:,:,s]-IMGsT1N[:,:,s].min())/(IMGsT1N[:,:,s].max()-IMGsT1N[:,:,s].min())\n",
        "#        if (IMGsT2W[:,:,s].max()-IMGsT2W[:,:,s].min()) != 0:\n",
        "#            IMGsT2W[:,:,s] = (IMGsT2W[:,:,s]-IMGsT2W[:,:,s].min())/(IMGsT2W[:,:,s].max()-IMGsT2W[:,:,s].min())\n",
        "#        if (IMGsT2F[:,:,s].max()-IMGsT2F[:,:,s].min()) != 0:\n",
        "#            IMGsT2F[:,:,s] = (IMGsT2F[:,:,s]-IMGsT2F[:,:,s].min())/(IMGsT2F[:,:,s].max()-IMGsT2F[:,:,s].min())\n",
        "\n",
        "#-- Saving step:\n",
        "#    with open('Lesion_Ref_Volumes_All_Dataset.json', 'w') as outfile:\n",
        "#        json.dump(volumes_dict, outfile)\n",
        "#    torch.save(Labels, \"Simplified_Labels_All_dataset.pt\") # tensor of simplified labels for each scan. The position in this tensor identifies the third dimension (== # of scan) in the segmentation and images tensors, i.e.: label[156] corresponds to entry [:,:,156] for any of the 3D tensors below.\n",
        "#    torch.save(SegIM.float(), \"Ref_Segmentation.pt\") # whole dataset tensor of reference segmentation\n",
        "#    torch.save(IMGsT1C.float(), \"T1C_All_dataset.pt\") # whole dataset tensor of T1 contrast imgs\n",
        "#    torch.save(IMGsT1N.float(), \"T1N_All_dataset.pt\") # whole dataset tensor of T1 non-contrast imgs\n",
        "#    torch.save(IMGsT2F.float(), \"T2F_All_dataset.pt\") # whole dataset tensor of T2 FLAIR imgs\n",
        "#    torch.save(IMGsT2W.float(), \"T2W_All_dataset.pt\") # whole dataset tensor of T2 contrast imgs\n",
        "#\n",
        "# END OF local PREPROCESSING ---------------------------------------------------"
      ],
      "metadata": {
        "id": "4GSwMilSWY38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset loading with google drive mounting\n",
        "The result of the local pre-processing were uploaded in google drive. The following lines of code implement the drive mount on colab, which allows to load the data from the drive without requiring implementing REST requests functions.\n",
        "\n",
        "Link to drive folder containing the data: https://drive.google.com/drive/folders/13Ne8UOwpfebXg6mvf7ZMPAhSaBnaeugX?usp=drive_link"
      ],
      "metadata": {
        "id": "Knpszrg3Wtw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZCdFOWQWYkc",
        "outputId": "6d4bb849-07af-40a8-e5bc-3acfdc79a755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset loading from preprocessed tensors. The data refer to patients 000 to 048.\n",
        "DataPath = \"./gdrive/MyDrive/BME630/\"\n",
        "Labels = torch.load(DataPath + \"Simplified_Labels_All_dataset.pt\") # tensor of simplified labels for each scan. The position in this tensor identifies the third dimension (== # of scan) in the segmentation and images tensors, i.e.: label[156] corresponds to entry [:,:,156] for any of the 3D tensors below.\n",
        "Seg = torch.load(DataPath + \"Ref_Segmentation.pt\") # tensor of reference segmentation\n",
        "T1C = torch.load(DataPath + \"T1C_All_dataset.pt\") # tensor of T1 contrast imgs\n",
        "T1N = torch.load(DataPath + \"T1N_All_dataset.pt\") # tensor of T1 non-contrast imgs\n",
        "T2F = torch.load(DataPath + \"T2F_All_dataset.pt\") # tensor of T2 FLAIR imgs\n",
        "T2W = torch.load(DataPath + \"T2W_All_dataset.pt\") # tensor of T2 contrast imgs"
      ],
      "metadata": {
        "id": "Ee9BhZNDW_UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dividing the dataset in training, test and validation"
      ],
      "metadata": {
        "id": "aR5KlRodZM3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since we want to provide an input that corresponds to 4 scans of the same patient, obtained with different methods (t1c, t1n, t2w, t2f) but referring to the same brain slice, to separate training, test and validation set while retaining this info we have to divide the dataset by working on the indexes of the scan arrays that were obtained from the preprocessing step. In other words, train_test_split input is an array of indexes, that go from 0 to len(Labels).\n",
        "# The stratification is performed on the Labels array, which contains the simplified class label info for each slice.\n",
        "IDX = np.arange(0, len(Labels))\n",
        "Idx_train, Idx_test, Labels_train, Labels_test = train_test_split(IDX, Labels, test_size=0.2, stratify=Labels, random_state=0)\n",
        "# Dividing training set in train e validation sets:\n",
        "IDX_train = np.arange(0, len(Labels_train))\n",
        "Idx_train, Idx_val, Labels_train, Labels_val = train_test_split(IDX_train, Labels_train, test_size=0.2, stratify=Labels_train, random_state=0)\n",
        "\n",
        "# Training set:\n",
        "# The labels vector is the same for all 4 sets, and is Labels_train.\n",
        "T1C_train = T1C[:,:,Idx_train]\n",
        "T1N_train = T1N[:,:,Idx_train]\n",
        "T2F_train = T2F[:,:,Idx_train]\n",
        "T2W_train = T2W[:,:,Idx_train]\n",
        "Seg_train = Seg[:,:,Idx_train]\n",
        "\n",
        "# Validation set:\n",
        "# The labels vector is the same for all 4 sets, and is Labels_val.\n",
        "T1C_val = T1C[:,:,Idx_val]\n",
        "T1N_val = T1N[:,:,Idx_val]\n",
        "T2F_val = T2F[:,:,Idx_val]\n",
        "T2W_val = T2W[:,:,Idx_val]\n",
        "Seg_val = Seg[:,:,Idx_val]\n",
        "\n",
        "# Test set:\n",
        "# The labels vector is the same for all 4 sets, and is Labels_test.\n",
        "T1C_test = T1C[:,:,Idx_test]\n",
        "T1N_test = T1N[:,:,Idx_test]\n",
        "T2F_test = T2F[:,:,Idx_test]\n",
        "T2W_test = T2W[:,:,Idx_test]\n",
        "Seg_test = Seg[:,:,Idx_test]\n",
        "\n",
        "print(\"---- Dataset info ----\")\n",
        "print(\"Dataset dimensions per type of scan:\\n\\t- Whole dataset: {} scans ({} per image type);\\n\\t- Training set: {} scans ({} per image type);\\n\\t- Validation set: {} scans ({} per image type);\\n\\t- Test set: {} scans ({} per image type)\".format(Labels.shape[0]*4,Labels.shape[0], Labels_train.shape[0]*4,Labels_train.shape[0], Labels_val.shape[0]*4,Labels_val.shape[0], Labels_test.shape[0]*4,Labels_test.shape[0]))\n",
        "print(\"Each dataset is further divided in 4 subsets, because we have: T1, T1 contrast, T2 an T2 FLAIR scans. Each scan is {} x {} pixels.\".format(Seg[:,:,0].shape[0],Seg[:,:,0].shape[1]))\n",
        "\n",
        "print(\"\\n---- Classes distribution in the dataset per type of scan ----\\nOverall there are:\\n\\t- {} scans of class 0 (= healthy tissue)\\n\\t- {} scans of class 1 (= tumor lesions)\".format(len(np.where(Labels==0.0)[0]), len(np.where(Labels==1.0)[0])))\n",
        "print(\"Concerning the datasets, there are:\\n\\t- Training set: \\n\\t\\t- {} class 0 scans\\n\\t\\t- {} class 1 scans\\n\\t- Validation set: \\n\\t\\t- {} class 0 scans\\n\\t\\t- {} class 1 scans\\n\\t- Test set: \\n\\t\\t- {} class 0 scans\\n\\t\\t- {} class 1 scans\".format(len(np.where(Labels_train==0.0)[0]), len(np.where(Labels_train==1.0)[0]), len(np.where(Labels_val==0.0)[0]), len(np.where(Labels_val==1.0)[0]), len(np.where(Labels_test==0.0)[0]), len(np.where(Labels_test==1.0)[0])))\n",
        "\n",
        "print(\"\\nPlotting of the same slice from different scans to prove that the same scan id applied to the 4 scan types tensors returns the exact same brain slice of the same patient:\")\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.subplot(221)\n",
        "plt.imshow(T1N[:,:,55], cmap=\"gray\")\n",
        "plt.title(\"T1N - patient 000, scan 55\")\n",
        "plt.show()\n",
        "plt.subplot(222)\n",
        "plt.imshow(T1C[:,:,55], cmap=\"gray\")\n",
        "plt.title(\"T1C - patient 000, scan 55\")\n",
        "plt.show()\n",
        "plt.subplot(223)\n",
        "plt.imshow(T2W[:,:,55], cmap=\"gray\")\n",
        "plt.title(\"T2 - patient 000, scan 55\")\n",
        "plt.show()\n",
        "plt.subplot(224)\n",
        "plt.imshow(T2F[:,:,55], cmap=\"gray\")\n",
        "plt.title(\"T2F - patient 000, scan 55\")\n",
        "plt.show()\n",
        "# second patient:\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.subplot(221)\n",
        "plt.imshow(T1N[:,:,210], cmap=\"gray\")\n",
        "plt.title(\"T1N - patient 002, scan 55\")\n",
        "plt.show()\n",
        "plt.subplot(222)\n",
        "plt.imshow(T1C[:,:,210], cmap=\"gray\")\n",
        "plt.title(\"T1C - patient 002, scan 55\")\n",
        "plt.show()\n",
        "plt.subplot(223)\n",
        "plt.imshow(T2W[:,:,210], cmap=\"gray\")\n",
        "plt.title(\"T2 - patient 002, scan 55\")\n",
        "plt.show()\n",
        "plt.subplot(224)\n",
        "plt.imshow(T2F[:,:,210], cmap=\"gray\")\n",
        "plt.title(\"T2F - patient 002, scan 55\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J1oV4G9-XLW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grouping data for correct input size and batch definition\n",
        "The following lines rearrange the data in a format that is suitable for the network, i.e. in the [tensor_depth, #_channels, img_height, img_width] format."
      ],
      "metadata": {
        "id": "0prUtCQiZX6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NumScans = 4\n",
        "# Initializing 4D tensors for the three subsets:\n",
        "X_train = torch.zeros(len(Labels_train), NumScans, T1C[:,:,0].shape[0], T1C[:,:,0].shape[1]) # creating a 4D tensor that groups the brain slices in 3D tensors of 4 scans.\n",
        "X_val = torch.zeros(len(Labels_val), NumScans, T1C[:,:,0].shape[0], T1C[:,:,0].shape[1])\n",
        "X_test = torch.zeros(len(Labels_test), NumScans, T1C[:,:,0].shape[0], T1C[:,:,0].shape[1])\n",
        "# The train, validation and test tensors are arranged in the shape [scan_#, n_channels, height, width] because of the type of input required for the network.\n",
        "for i in range(len(Labels_train)):\n",
        "    X_train[i,0,:,:]=T1N_train[:,:,i] # T1\n",
        "    X_train[i,1,:,:]=T1C_train[:,:,i] # T1 contrast\n",
        "    X_train[i,2,:,:]=T2W_train[:,:,i] # T2\n",
        "    X_train[i,3,:,:]=T2F_train[:,:,i] # T2 FLAIR\n",
        "\n",
        "for i in range(len(Labels_val)):\n",
        "    X_val[i,0,:,:]=T1N_val[:,:,i] # T1\n",
        "    X_val[i,1,:,:]=T1C_val[:,:,i] # T1 contrast\n",
        "    X_val[i,2,:,:]=T2W_val[:,:,i] # T2\n",
        "    X_val[i,3,:,:]=T2F_val[:,:,i] # T2 FLAIR\n",
        "\n",
        "for i in range(len(Labels_test)):\n",
        "    X_test[i,0,:,:]=T1N_test[:,:,i] # T1\n",
        "    X_test[i,1,:,:]=T1C_test[:,:,i] # T1 contrast\n",
        "    X_test[i,2,:,:]=T2W_test[:,:,i] # T2\n",
        "    X_test[i,3,:,:]=T2F_test[:,:,i] # T2 FLAIR"
      ],
      "metadata": {
        "id": "VrAfElRrXeIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric Dictionary for miseval:\n",
        "By manually importing the miseval package functions, we need to include this snippet of code to handle the attributes passing for the function \"evaluate\", which computes the metrics on the segmentation images."
      ],
      "metadata": {
        "id": "izC5oGmaZfZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_dict = {\n",
        "  \"TruePositive\": calc_TruePositive,\n",
        "  \"TrueNegative\": calc_TrueNegative,\n",
        "  \"FalsePositive\": calc_FalsePositive,\n",
        "  \"FalseNegative\": calc_FalseNegative,\n",
        "  \"TP\": calc_TruePositive,\n",
        "  \"TN\": calc_TrueNegative,\n",
        "  \"FP\": calc_FalsePositive,\n",
        "  \"FN\": calc_FalseNegative,\n",
        "  \"DSC\": calc_DSC_Enhanced,\n",
        "  \"Dice\": calc_DSC_Enhanced,\n",
        "  \"DiceSimilarityCoefficient\": calc_DSC_Enhanced,\n",
        "  \"IoU\": calc_IoU_Sets,\n",
        "  \"Jaccard\": calc_IoU_Sets,\n",
        "  \"IntersectionOverUnion\": calc_IoU_Sets,\n",
        "  \"ACC\": calc_Accuracy_Sets,\n",
        "  \"Accuracy\": calc_Accuracy_Sets,\n",
        "  \"AUC\": calc_AUC_trapezoid,\n",
        "  \"AUC_trapezoid\": calc_AUC_trapezoid,\n",
        "  \"Sensitivity\": calc_Sensitivity_Sets,\n",
        "  \"SENS\": calc_Sensitivity_Sets,\n",
        "  \"TPR\": calc_Sensitivity_Sets,\n",
        "  \"TruePositiveRate\": calc_Sensitivity_Sets,\n",
        "  \"Recall\": calc_Sensitivity_Sets,\n",
        "  \"SPEC\": calc_Specificity_Sets,\n",
        "  \"Specificity\": calc_Specificity_Sets,\n",
        "  \"TNR\": calc_Specificity_Sets,\n",
        "  \"TrueNegativeRate\": calc_Specificity_Sets,\n",
        "  \"PREC\": calc_Precision_Sets,\n",
        "  \"Precision\": calc_Precision_Sets\n",
        "  }"
      ],
      "metadata": {
        "id": "tDxwDBmoZdX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network run: Training phase\n",
        "The training phase here is implemented with the validation set regularization, i.e. an early stopping condition is defined when the loss value on the validation data for one epoch is greater than the loss two epochs before. This check is done from the 3rd training epoch on.\n",
        "\n",
        "The training is performed using three for loops: on the learning rate value, on the epochs and on the training set batches, respectively from outer to inner loop. This is because the idea is to train the same network for different learning rates to identify the most suitable for our architecture. The training is divided in 100 batches, which means that every batch has 46 samples."
      ],
      "metadata": {
        "id": "4US4BHxpZ1tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#---- Training phase:\n",
        "# User definition of # classes to identify:\n",
        "print(\"\\nPlease selected the number of classes you want to consider between:\\n\\t- 2 (simplified segmentation)\\n\\t- 4 (complete segmentation)\")\n",
        "while True:\n",
        "    uin = input(\"> \")\n",
        "    if int(uin) == 2 or int(uin) == 4:\n",
        "        break\n",
        "    else:\n",
        "        print(\"It looks like something went wrong. Please retry and ensure you type either 2 or 4.\")\n",
        "n_classes = int(uin)\n",
        "if n_classes == 2: # converts the 4-classes segmentation masks in binary masks.\n",
        "    Seg_train[Seg_train!=0.0]=1.0\n",
        "    Seg_val[Seg_val!=0.0]=1.0\n",
        "    Seg_test[Seg_test!=0.0]=1.0\n",
        "print(\"Running the network using {} classes\".format(uin))\n",
        "\n",
        "# This will allow the network to run on GPUs\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "print(\"\\n---- Run settings info: ----\\nRunning using: \", device)\n",
        "\n",
        "# learning rate:\n",
        "learning_rate = np.round(np.linspace(0.005, 0.02, 10),4)\n",
        "# momentum:\n",
        "mom = 0.9 # momentum applied to the stochastic gradient descent algorithm; helps to direct the descent towards the direction of steeper decrease,\n",
        "# allowing the use of higher learning rates and the algorithm to converge faster. 0,9 is a commonly used value, but it can be optimized as one of the network parameters.\n",
        "\n",
        "# Loss function: Cross Entropy loss. Preferred because it allows to evaluate the loss even when we deal with more than 2 classes,\n",
        "# which might be the case in this application. A weight vector can be provided to the loss function in case the dataset has an unbalanced representation of the classes.\n",
        "# This method is applied only if the performance without the class weight is suboptimal.\n",
        "# if n_classes == 2:\n",
        "#  class_weights = torch.tensor([1, 5])\n",
        "# else:\n",
        "#  class_weights = torch.tensor([1, 3, 5, 20]) # the first is for class 0, the second for cl 1, the third for cl 2 and the third for cl 3. Could be improved by using a weight that is proportional to each class size.\n",
        "# For now, the weight increases from class 0 to 3 because the classes are progressively less represented in the dataset. class 1 and class 2 (tumor core and edema) have closer weights because they make the majority of tumor tissues.\n",
        "loss_function = nn.CrossEntropyLoss() # with weights: loss_function = nn.CrossEntropyLoss(class_weights)\n",
        "loss_function.to(device)\n",
        "\n",
        "# Number of batches:\n",
        "n_batches = 100\n",
        "elem_in_batch = round(X_train.shape[0]/n_batches) # elements in a single training batch\n",
        "# Training epochs:\n",
        "epochs = 300\n",
        "\n",
        "# Since we are not implementing batches on the validation, we can push the related data to the device already:\n",
        "X_val.to(device)    # validation data\n",
        "Seg_val.to(device)  # validation segmentation\n",
        "\n",
        "print(\"\\n---- Network RUN - parameters optimization ----\")\n",
        "for lr in learning_rate:\n",
        "    # Net creation:\n",
        "    # Simpler architecture:\n",
        "    net_name = \"SimpleUnet\"\n",
        "    net = SimpleUnet(4, n_classes)\n",
        "    # More complex architecture: uncomment the next line and comment the previous to implemet the second network architecture.\n",
        "    # net = BiggerUnet(4, n_classes)\n",
        "    # net_name = \"BiggerUnet\"\n",
        "\n",
        "    net.to(device)\n",
        "    # Number of trainable parameters:\n",
        "    total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "    # Printing network info:\n",
        "    print(\"Network info:\")\n",
        "    print(\"\\t- Number of classes: {}\\n\\t- Number of training batches: {}\\n\\t- Elements in a single batch: {}\\n\\t- Loss function: Cross Entropy\\n\\t- Momentum: {}\\n\\t- Number of trainable parameters: {}\\n\\t- Current learning rate: {}\".format(n_classes, n_batches, elem_in_batch, mom, total_params,lr))\n",
        "    print(\"Network architecture:\\n\", net)\n",
        "    # optimizer: SGD\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=mom)\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    for epoch in range(epochs):\n",
        "        if epoch == 0 or epoch % 10 == 0:\n",
        "            print(\"Epoch # \"+str(epoch))\n",
        "        avg_loss = 0 # average loss for the 10 batches, calculated every epoch.\n",
        "        for batches in range(n_batches):\n",
        "            print(\"\\tUsing batch # \"+str(batches+1))\n",
        "            if batches < 9: # broken down with an if statement because the # of samples in the training set is 4563, which divided by 10 (# of batches) returns 456,3. Considering each batch made of 456 elements, the last one has 456 + 3 = 459 elements, which in order ot be considered require a different x and y definition.\n",
        "                x = X_train[batches*elem_in_batch:elem_in_batch+batches*elem_in_batch, :, :, :]\n",
        "                y = Seg_train[:, :, batches*elem_in_batch:elem_in_batch+batches*elem_in_batch]\n",
        "            else:\n",
        "                x = X_train[batches*elem_in_batch:-1, :, :, :]\n",
        "                y = Seg_train[:, :, batches*elem_in_batch:-1]\n",
        "            x.to(device)\n",
        "            y.to(device)\n",
        "            # Set network to training mode:\n",
        "            net.train()\n",
        "            # Training using the batch data (x) and the associated labels (y):\n",
        "            singleBatch_loss = train(net, x, y, loss_function)\n",
        "            # adding the current batch loss to the avg_loss:\n",
        "            avg_loss += singleBatch_loss\n",
        "        train_loss.append(avg_loss/n_batches)\n",
        "\n",
        "        # Setting network in evaluation mode:\n",
        "        net.eval()\n",
        "        # Evaluating the loss on the validation set as early stopping condition on training to avoid overfitting:\n",
        "        validate(net, X_val, Seg_val, loss_function, val_loss)\n",
        "        if epoch == 0 or epoch % 10 == 0:\n",
        "            print(\"\\t Train loss = {}\\t\\t Validation loss = {}\".format(train_loss[epoch], val_loss[epoch]))\n",
        "        if epoch > 2:\n",
        "            if val_loss[epoch] > val_loss[epoch-2]: # considering 2 epochs before allows to have a bit of flexibility if the loss on the validation has slight fluctuations. This could be improved by introducing a threshold on the difference between validation losses, such that if the val_loss fluctuates for several epochs but the relative difference with previous epochs is small, the training can go on anyway.\n",
        "               print(\"\\tEarly stopping at iteration # \"+str(epoch+1))\n",
        "               break\n",
        "    # Loss function on epochs plot:\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(train_loss, range(1,epochs+1), 'r', label=\"Train loss\")\n",
        "    plt.plot(val_loss, range(1,epochs+1), 'b', labels=\"Val loss\")\n",
        "    plt.title(\"Cross Entropy loss - L.R. = \"+str(lr))\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    # Saving the figure:\n",
        "    try:\n",
        "      figname = net_name+\"LR_\"+str(lr)+\".jpg\"\n",
        "      plt.savefig(figname)\n",
        "    except:\n",
        "      print(\"Unable to save \"+figname)\n",
        "    # Saving the model:\n",
        "    net_name = net_name+\"_LR_\"+str(lr)+\".pt\"\n",
        "    torch.save(net.state_dict(), net_name)"
      ],
      "metadata": {
        "id": "XWrn4JFNXksL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network Run: Testing phase\n",
        "The testing phase is performed only on the best model that we obtained out of the training phase. The best model is defined as the one having the highest learning rate while providing a reasonable loss on the training and the test data. If the script is run on a cluster, the testing can be commented and evaluated at a later moment since it requires the definition of the best model's name either in the code (in place of the 'None' of net_name) or user provided via input method.\n",
        "\n",
        "The testing phase implements the miseval functions to evaluate the goodness of the segmentation. The scores calculated are:\n",
        "- Dice score;\n",
        "- Jaccard score (or Intersection over Union score);\n",
        "- the usual accuracy, precision, sensitivity and specificity scores of the related confusion matrix."
      ],
      "metadata": {
        "id": "Sz477A-ibtVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#---- Best model evaluation:\n",
        "# Model loading:\n",
        "net_name = None\n",
        "if net_name is None:\n",
        "    print(\"Please specify the name of the file containing the network you want to upload:\")\n",
        "    while True:\n",
        "        uin2 = input(\"> \")\n",
        "        if os.path.exists(str(uin2)):\n",
        "            break\n",
        "        else:\n",
        "            print(\"Unable to find the requested file. Please try again...\")\n",
        "net = SimpleUnet(n_classes) # reinitialize model; the load_state_dict saved all the params that will be reapplied in the next line of code\n",
        "net.load_state_dict(torch.load(net_name))\n",
        "# Evaluation on test\n",
        "net.to(device)\n",
        "net.eval()\n",
        "X_test.to(device)   # test data\n",
        "Seg_test.to(device) # test segmentation\n",
        "with torch.no_grad():\n",
        "  Dice, Jacc, Acc, Prec, Sens, Rec, pred_seg, real_seg = test(net, X_test, Seg_test, n_classes)"
      ],
      "metadata": {
        "id": "4wqd6r5ZXoPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segmentation visualization"
      ],
      "metadata": {
        "id": "8LBG2FBw0vMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot of the segmentations for comparison:\n",
        "# Plot # 1:\n",
        "plt.figure(figsize=(10,4))\n",
        "# Real segmentation:\n",
        "plt.subplot(121)\n",
        "plt.imshow(real_seg[1,0,:,:])\n",
        "plt.title(\"Ref. segmentation - Test set slice 2\")\n",
        "plt.show()\n",
        "# Network generated segmentation:\n",
        "plt.subplot(122)\n",
        "plt.imshow(pred_seg[1,0,:,:])\n",
        "plt.title(\"Pred. segmentation - Test set slice 2\")\n",
        "plt.show()\n",
        "\n",
        "# Plot # 2:\n",
        "plt.figure(figsize=(10,4))\n",
        "# Real segmentation:\n",
        "plt.subplot(121)\n",
        "plt.imshow(real_seg[2,0,:,:])\n",
        "plt.title(\"Ref. segmentation - Test set slice 3\")\n",
        "plt.show()\n",
        "# Network generated segmentation:\n",
        "plt.subplot(122)\n",
        "plt.imshow(pred_seg[2,0,:,:])\n",
        "plt.title(\"Pred. segmentation - Test set slice 3\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FO9RUqEt00SQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}